---
title: 음성처리개론 3
---

# 음성처리개론 3

## 음성 신호와 딥러닝

- 학습 데이터
    - 일반적으로 최소한 <TEXT, AUDIO> 쌍
    - 문자 데이터
        - 연구 자료가 많고 구현이 쉬운 것은 단연 영어. 한국어 발화와 한국어 레이블로 학습하는 것은 난이도가 높음
            - 다국어 연구가 어려운 작업: 음성인식, 음성 합성(음향 모델)
            - 다국여 상관 없음: 잡음 제거, 화자 인식, 음성 합성(보코더)
            - \* 같은 음성 합성이더라도 음향 모델 부분과 보코더 부분이 다름. 음향모델은 텍스트로부터 멜 스펙트로그램을 생성하므로 언어처리와 밀접한 부분. 보코더는 멜 스펙트로그램에서 오디오를 만들기 때문에 언어 차이와 크게 관련 없음
    - 소리 데이터
        - 가청주파수: 20 ~ 16,000Hz
        - 시간, 진폭 등 정보로 이루어짐
        - 파동과 소리
            - 파동의 3요소: 진동수, 진폭, 위상
            - 소리의 3요소: 고저, 음량, 음색

- 음성 신호와 관련된 태스크
    - VUI/VUX 기술 구성
        - 음성인식 STT
            - 음성검출 VAD
            - 끝점검출 EPD
            - 화자인식 및 화자분리
            - 실시간 잡음 제거 (noise reduction)
        - 음성합성 TTS
            - 음향모델 (acoustic model): 
            - 보코더 (vocoder)
    - 그 외
        - 음원 분리 (악기 분리)
        - 업샘플링: 해상도 높이기
        - 음성 변환: 기존 음성의 음색을 다른 음색으로 변경
        - 가창 합성: 음계까지 오디오 데이터에 붙여서 노래하는 음성을 생성

- 음성 데이터를 활용한 학습의 목표
    - 음성 데이터 학습의 난점
        - 레이블 '안녕하세요'에 대해 실제 오디오는 1초에 22500여개의 데이터가 존재. (샘플링레이트가 22500이라고 한다면)
        - 따라서 문자와 음성 데이터 간의 적절한 정렬이 중요

- 딥러닝 기초 지식
    - Fully-connected Layer: ANN
    - Convolutional Layer: 시신경 모방
    - Recurrent: RNN
    - Transformer
    - Diffusion, Flow

- Fully-connected Layer
    - 층 마다 각각의 노드가 서로 연결
    - 가장 초기 딥러닝 모델
    - 간단한 분류에는 최근에도 자주 사용
    - CNN, LSTM 사용시 입력 크기로부터 특정 크기로 출력 크기를 제안해야 할 때 사용
    - 드롭아웃: 다 연결하지 말고 중요한 것들 연결

- Convolutional Layer
    - 이미지의 구조적 정보, 특징을 점차 한정해가면서 학습
    - 트랜스포머 내부에도 있음

- RNN
    - 순차적으로 이전 레이어의 값을 참조해서 다음 계산
    - 자연어처리 쪽에 많이 사용됨
    - 네트워크가 깊어지면 0에 수렴하게 되어 역전파시 가중치 수정이 잘 이뤄지지 않게 됨

- LSTM
    - 이전 값을 얼마나 기억할지 계산하여 RNN의 문제점 해소
    - 반대방향으로도 학습하게 하는 BiLSTM도 있음

- 트랜스포머
    - 어텐션 개념이 도임됨
        - [참고](https://distill.pub/2016/augmented-rnns/)
        - 여러 단어로 구성된 문장을 번역하는 모델이라면, 이전 방식의 경우 단어 단위로 인풋 값이 순차적으로 들어가고, 그에 대응하는 번역어가 나오게 될 것임.
        - 이를 각 단어에 위치 값을 포함시켜 한 번에 입력하는 방식
    - 인코더와 디코더로 구성됨
    - 음성 분야에서는 문자와 스펙트로그램을 어텐션을 통해 매치시켜 한 번에 계산 가능
        - 음성 합성 연구에서는 18-19년 이전에는 LSTM 계열이 주류였으나, 이 시기 이후 트랜스포머로 많이 옮겨감
    - 비전 분야에서도 부분 부분을 한 번에 입력하기 때문에 이점이 있음
    - 소프트맥스: 높은 확률 …

- Diffusion
    - 생성 모델에 사용
    - 18-20년: VAE, GAN과 같은 모델 활용 연구 주류
    - 최근: Flow, Diffusion(달리)
    - Diffusion: 노이즈에서 시작해서 원하는 형태로 깎아나감.
        - 학습시간이 오래 걸린다는 단점. 그러나 요즘 하드웨어 성능 발전