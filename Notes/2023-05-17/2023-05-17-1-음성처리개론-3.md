---
title: 음성처리개론 3
---

# 음성처리개론 3

## 음성 신호와 딥러닝

- 학습 데이터
    - 일반적으로 최소한 <TEXT, AUDIO> 쌍
    - 문자 데이터
        - 연구 자료가 많고 구현이 쉬운 것은 단연 영어. 한국어 발화와 한국어 레이블로 학습하는 것은 난이도가 높음
            - 다국어 연구가 어려운 작업: 음성인식, 음성 합성(음향 모델)
            - 다국여 상관 없음: 잡음 제거, 화자 인식, 음성 합성(보코더)
            - \* 같은 음성 합성이더라도 음향 모델 부분과 보코더 부분이 다름. 음향모델은 텍스트로부터 멜 스펙트로그램을 생성하므로 언어처리와 밀접한 부분. 보코더는 멜 스펙트로그램에서 오디오를 만들기 때문에 언어 차이와 크게 관련 없음
    - 소리 데이터
        - 가청주파수: 20 ~ 16,000Hz
        - 시간, 진폭 등 정보로 이루어짐
        - 파동과 소리
            - 파동의 3요소: 진동수, 진폭, 위상
            - 소리의 3요소: 고저, 음량, 음색

- 음성 신호와 관련된 태스크
    - VUI/VUX 기술 구성
        - 음성인식 STT
            - 음성검출 VAD
            - 끝점검출 EPD
            - 화자인식 및 화자분리
            - 실시간 잡음 제거 (noise reduction)
        - 음성합성 TTS
            - 음향모델 (acoustic model): 
            - 보코더 (vocoder)
    - 그 외
        - 음원 분리 (악기 분리)
        - 업샘플링: 해상도 높이기
        - 음성 변환: 기존 음성의 음색을 다른 음색으로 변경
        - 가창 합성: 음계까지 오디오 데이터에 붙여서 노래하는 음성을 생성

- 음성 데이터를 활용한 학습의 목표
    - 음성 데이터 학습의 난점
        - 레이블 '안녕하세요'에 대해 실제 오디오는 1초에 22500여개의 데이터가 존재. (샘플링레이트가 22500이라고 한다면)
        - 따라서 음소에 대한 오디오 데이터 정렬이 중요