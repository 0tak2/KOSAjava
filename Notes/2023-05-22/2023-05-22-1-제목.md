---
title: 자연어 처리 1
---

# 자연어 처리 1

## 개요

## 자연어의 이해

### TF/IDF

- 목표
- TF: 특정 단어가 한 문서에서 얼마나 출현했는가?
- DF: 특정 단어가 몇 개의 문서에 출현했는가?
- IDF: DF 값의 역수

### 워드 임베딩

단어를 덴스 벡터로 표현

## 어텐션

디코더에서 출력 단어를 예측하는 매 시점마다 인코더에서의 전체 입력 문장을 참고한다는 아이디어
현재 시점의 예측 단어와 관련있는 부분에 집중하여 본다

소프트맥스 - 모든 값들을 더하면 1이 되도록 만들어줌
모든 Q를 K가 생길 때마다 내적하고, 그 결과를 소프트맥스를 통해 분포로 만든다.
그 분포에 따라 관련 데이터는 반영이 많이 된다.

## 사례

- NH 카드 톡봇 IRQA 성능 개선 위한 SLX-BERT 임베딩 모델 학습 및 적용
    - 기존 BERT 모델은 그냥 책만 많이 읽은 모델. 수정 보완.

- 통일부 뉴스 기사 신뢰도
    - 북한 뉴스와 유사도를 분석하여 신뢰도 산출

- AMICUS LEX 범률분서 분류
    - 기존 BERT 모델을 법률 도메인에 특화되도록 추가 합습

    
