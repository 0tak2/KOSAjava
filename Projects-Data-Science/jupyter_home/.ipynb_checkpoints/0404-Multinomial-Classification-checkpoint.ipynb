{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fdcab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules imported!\n"
     ]
    }
   ],
   "source": [
    "# Modules Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 학습 데이터와 테스트 데이터 분리 (일반적으로 7:3 혹은 8:2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 정규화\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 이번에 사용할 데이터에는 결측치와 이상치가 없음\n",
    "\n",
    "# 텐서플로우 - 케라스\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam # 항상 평균 이상의 성능\n",
    "\n",
    "# 다중 분류를 위해 one-hot encoding 필요\n",
    "import tensorflow as tf\n",
    "\n",
    "print('modules imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a76fb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  height  weight\n",
       "0      1     188      71\n",
       "1      2     161      68\n",
       "2      0     178      52\n",
       "3      2     136      63\n",
       "4      1     145      52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(20000, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Raw Data Loading\n",
    "\n",
    "df = pd.read_csv('./data/bmi.csv', skiprows=3) # 4번째 줄부터 load. 1-3 라인은 정보가 적혀있음.\n",
    "display(df.head(), df.shape)\n",
    "\n",
    "# 이 데이터에는 결측치와 이상치는 존재하지 않으므로 넘어간다.\n",
    "# 실제 작업시에는 확인해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79599259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[198  67]\n",
      " [135  41]\n",
      " [190  58]\n",
      " ...\n",
      " [149  50]\n",
      " [126  64]\n",
      " [166  61]] (14000, 2)\n",
      "\n",
      "[[0.975      0.71111111]\n",
      " [0.1875     0.13333333]\n",
      " [0.875      0.51111111]\n",
      " ...\n",
      " [0.3625     0.33333333]\n",
      " [0.075      0.64444444]\n",
      " [0.575      0.57777778]] (14000, 2)\n",
      "\n",
      "\n",
      "[0 1 0 ... 1 2 1]\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 학습데이터와 테스트데이터를 분리\n",
    "\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df[['height', 'weight']].values, # train_test_split(df[['height', 'weight']]) # 알아서 df를 ndarray로 변환한다\n",
    "                 df['label'].values,\n",
    "                 test_size=0.3) # 7:3\n",
    "print(x_data_train, x_data_train.shape, end='\\n\\n') # (14000, 2)\n",
    "\n",
    "# 정규화\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data_train)\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "print(x_data_train_norm, x_data_train_norm.shape, end='\\n\\n\\n') # 정규화됨\n",
    "\n",
    "# one-hot 처리\n",
    "# t데이터는 클래스이므로 정규화는 필요 없으나, one-hot 인코딩 필요\n",
    "print(t_data_train, end='\\n\\n') # 현재 1차원. one-hot 처리 후 2차원\n",
    "\n",
    "t_data_train_onehot = tf.one_hot(t_data_train, depth=3).numpy() # depth는 클래스의 수 / numpy()를 통해 tf 타입을 numpy로 변환\n",
    "t_data_test_onehot = tf.one_hot(t_data_test, depth=3).numpy()\n",
    "print(t_data_train_onehot, end='\\n\\n')\n",
    "print(t_data_test_onehot, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed430e66",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid keyword argument(s) in `compile()`: ({'matrics'},). Valid keyword arguments include \"cloning\", \"experimental_run_tf_function\", \"distribute\", \"target_tensors\", or \"sample_weight_mode\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;66;03m# node 3개\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Model 설정\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m              \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical_crossentropy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmatrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 모델 평가시 정확성을 accuracy로 측정하도록 지정\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Model 학습\u001b[39;00m\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_data_train_norm,\n\u001b[0;32m     16\u001b[0m           t_data_train_onehot,\n\u001b[0;32m     17\u001b[0m           epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, \u001b[38;5;66;03m# 반복 횟수\u001b[39;00m\n\u001b[0;32m     18\u001b[0m           validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;66;03m# 전체 학습 데이터의 일부를 평가에 사용. 평가하면서 학습 진행\u001b[39;00m\n\u001b[0;32m     19\u001b[0m           verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_env\\lib\\site-packages\\keras\\engine\\training.py:3524\u001b[0m, in \u001b[0;36mModel._validate_compile\u001b[1;34m(self, optimizer, metrics, **kwargs)\u001b[0m\n\u001b[0;32m   3522\u001b[0m invalid_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(kwargs) \u001b[38;5;241m-\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   3523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m invalid_kwargs:\n\u001b[1;32m-> 3524\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid keyword argument(s) in `compile()`: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(invalid_kwargs,)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Valid keyword arguments include \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3527\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcloning\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperimental_run_tf_function\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistribute\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   3528\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   3529\u001b[0m     )\n\u001b[0;32m   3531\u001b[0m \u001b[38;5;66;03m# Model must be created and compiled with the same DistStrat.\u001b[39;00m\n\u001b[0;32m   3532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;129;01mand\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mhas_strategy():\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid keyword argument(s) in `compile()`: ({'matrics'},). Valid keyword arguments include \"cloning\", \"experimental_run_tf_function\", \"distribute\", \"target_tensors\", or \"sample_weight_mode\"."
     ]
    }
   ],
   "source": [
    "# 모델 만들기\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 추가\n",
    "model.add(Flatten(input_shape=(2,))) # node 2개\n",
    "model.add(Dense(3, activation='softmax')) # node 3개\n",
    "\n",
    "# Model 설정\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy', # 이항분류시 binary_crossentropy\n",
    "              matrics=['accuracy']) # 모델 평가시 정확성을 accuracy로 측정하도록 지정\n",
    "\n",
    "# Model 학습\n",
    "model.fit(x_data_train_norm,\n",
    "          t_data_train_onehot,\n",
    "          epochs=500, # 반복 횟수\n",
    "          validation_split=0.2, # 전체 학습 데이터의 일부를 평가에 사용. 평가하면서 학습 진행\n",
    "          verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
