{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c54662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported!\n"
     ]
    }
   ],
   "source": [
    "# Import Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print('imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb6c3c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/fmnist/fashion-mnist_train.csv')\n",
    "display(df.head(), df.shape) # (60000, 785)\n",
    "\n",
    "img_data = df.drop('label', axis=1, inplace=False).values\n",
    "fig = plt.figure()\n",
    "fig_arr = []\n",
    "\n",
    "for n in range(10):\n",
    "    fig_arr.append(fig.add_subplot(2,5,n+1))\n",
    "    fig_arr[n].imshow(img_data[n].reshape(28,28), cmap='Greys', interpolation='nearest')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ffdf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 데이터를 이용해 머신러닝해보기\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Prepareing Training Data Set\n",
    "# 1. 학습 데이터와 테스트 데이터 분리\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df.drop('label', axis=1, inplace=False).values,\n",
    "                 df['label']. values,\n",
    "                 test_size=0.2) # 8:2 비율\n",
    "\n",
    "# 2. 정규화\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data_train)\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "# 3. one-hot 처리는 스킵. keras를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f82c88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 242,762\n",
      "Trainable params: 242,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "269/269 [==============================] - 2s 4ms/step - loss: 1.0187 - accuracy: 0.7555 - val_loss: 0.4080 - val_accuracy: 0.8936\n",
      "Epoch 2/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.9084 - val_loss: 0.2840 - val_accuracy: 0.9229\n",
      "Epoch 3/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.2571 - accuracy: 0.9285 - val_loss: 0.2368 - val_accuracy: 0.9338\n",
      "Epoch 4/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.2167 - accuracy: 0.9389 - val_loss: 0.2069 - val_accuracy: 0.9423\n",
      "Epoch 5/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1874 - accuracy: 0.9481 - val_loss: 0.1896 - val_accuracy: 0.9439\n",
      "Epoch 6/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1656 - accuracy: 0.9537 - val_loss: 0.1730 - val_accuracy: 0.9519\n",
      "Epoch 7/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1465 - accuracy: 0.9598 - val_loss: 0.1611 - val_accuracy: 0.9565\n",
      "Epoch 8/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1315 - accuracy: 0.9636 - val_loss: 0.1508 - val_accuracy: 0.9571\n",
      "Epoch 9/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1191 - accuracy: 0.9664 - val_loss: 0.1394 - val_accuracy: 0.9622\n",
      "Epoch 10/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.1084 - accuracy: 0.9696 - val_loss: 0.1302 - val_accuracy: 0.9615\n",
      "Epoch 11/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9727 - val_loss: 0.1268 - val_accuracy: 0.9635\n",
      "Epoch 12/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0886 - accuracy: 0.9763 - val_loss: 0.1224 - val_accuracy: 0.9653\n",
      "Epoch 13/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0818 - accuracy: 0.9782 - val_loss: 0.1222 - val_accuracy: 0.9635\n",
      "Epoch 14/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0745 - accuracy: 0.9795 - val_loss: 0.1128 - val_accuracy: 0.9686\n",
      "Epoch 15/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0674 - accuracy: 0.9826 - val_loss: 0.1103 - val_accuracy: 0.9686\n",
      "Epoch 16/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9841 - val_loss: 0.1113 - val_accuracy: 0.9673\n",
      "Epoch 17/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0564 - accuracy: 0.9860 - val_loss: 0.1056 - val_accuracy: 0.9704\n",
      "Epoch 18/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0518 - accuracy: 0.9872 - val_loss: 0.1047 - val_accuracy: 0.9689\n",
      "Epoch 19/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9882 - val_loss: 0.1024 - val_accuracy: 0.9701\n",
      "Epoch 20/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0432 - accuracy: 0.9896 - val_loss: 0.1065 - val_accuracy: 0.9688\n",
      "Epoch 21/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0399 - accuracy: 0.9905 - val_loss: 0.1044 - val_accuracy: 0.9689\n",
      "Epoch 22/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0363 - accuracy: 0.9919 - val_loss: 0.1015 - val_accuracy: 0.9710\n",
      "Epoch 23/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.9924 - val_loss: 0.0988 - val_accuracy: 0.9720\n",
      "Epoch 24/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.9936 - val_loss: 0.1007 - val_accuracy: 0.9717\n",
      "Epoch 25/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9947 - val_loss: 0.0960 - val_accuracy: 0.9731\n",
      "Epoch 26/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0250 - accuracy: 0.9951 - val_loss: 0.0985 - val_accuracy: 0.9714\n",
      "Epoch 27/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0232 - accuracy: 0.9955 - val_loss: 0.0956 - val_accuracy: 0.9728\n",
      "Epoch 28/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.9961 - val_loss: 0.0996 - val_accuracy: 0.9731\n",
      "Epoch 29/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0185 - accuracy: 0.9969 - val_loss: 0.0995 - val_accuracy: 0.9714\n",
      "Epoch 30/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9971 - val_loss: 0.1006 - val_accuracy: 0.9707\n",
      "Epoch 31/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0153 - accuracy: 0.9976 - val_loss: 0.0969 - val_accuracy: 0.9731\n",
      "Epoch 32/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0136 - accuracy: 0.9981 - val_loss: 0.0999 - val_accuracy: 0.9726\n",
      "Epoch 33/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0121 - accuracy: 0.9986 - val_loss: 0.1024 - val_accuracy: 0.9711\n",
      "Epoch 34/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0109 - accuracy: 0.9987 - val_loss: 0.1012 - val_accuracy: 0.9728\n",
      "Epoch 35/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9986 - val_loss: 0.1064 - val_accuracy: 0.9699\n",
      "Epoch 36/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0092 - accuracy: 0.9989 - val_loss: 0.0994 - val_accuracy: 0.9729\n",
      "Epoch 37/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9993 - val_loss: 0.1045 - val_accuracy: 0.9717\n",
      "Epoch 38/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.1010 - val_accuracy: 0.9732\n",
      "Epoch 39/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.1086 - val_accuracy: 0.9728\n",
      "Epoch 40/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.1008 - val_accuracy: 0.9744\n",
      "Epoch 41/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0049 - accuracy: 0.9997 - val_loss: 0.1032 - val_accuracy: 0.9723\n",
      "Epoch 42/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.1055 - val_accuracy: 0.9731\n",
      "Epoch 43/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.1056 - val_accuracy: 0.9744\n",
      "Epoch 44/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.1065 - val_accuracy: 0.9744\n",
      "Epoch 45/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9735\n",
      "Epoch 46/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9743\n",
      "Epoch 47/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9743\n",
      "Epoch 48/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9737\n",
      "Epoch 49/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9737\n",
      "Epoch 50/50\n",
      "269/269 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26c3ca43fa0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 생성\n",
    "model = Sequential()\n",
    "\n",
    "# 모델에 레이어 추가\n",
    "# input layer\n",
    "model.add(Flatten(input_shape=(784,))) # 28*28\n",
    "# hidden layer\n",
    "model.add(Dense(256, activation='relu')) # Hidden Layer의 activation은 relu로 잡는다. sigmoid로 잡으면 전파가 되지 않는다.\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax')) # 0~9\n",
    "\n",
    "print(model.summary()) # 현재 레이어가 어떻게 구성되어 있는지 출력.\n",
    "# Param은 w를 의미한다. 한 번 계산할 때마다 편미분이 필요하다. (Total params: 242,762)\n",
    "# 많은 계산이 필요하게 되는 것이다.\n",
    "\n",
    "# 모델 설정\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy', # one-hot + crossentropy\n",
    "              metrics=['accuracy']) # 평가 기준\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(x_data_train_norm, # 우리 데이터가 간단하므로 크게 느려지지는 않을 것이다.\n",
    "          t_data_train,\n",
    "          epochs=50,\n",
    "          validation_split=0.2,\n",
    "          verbose=1,\n",
    "          batch_size=100)\n",
    "# val_accuracy: 0.8851\n",
    "# 정확도가 높아지기는 했지만, 생각보다 상승 폭이 크지 않다. 과적합이 발생했을 가능성이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d37c023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9700\n",
      "[0.14679686725139618, 0.9700000286102295]\n"
     ]
    }
   ],
   "source": [
    "# 만든 모델에 대한 최종 평가\n",
    "print(model.evaluate(x_data_test_norm, t_data_test)) # [0.35582849383354187, 0.8851666450500488]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "694a5a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 242,762\n",
      "Trainable params: 242,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "384/384 [==============================] - 2s 5ms/step - loss: 1.1574 - accuracy: 0.6110 - val_loss: 0.6430 - val_accuracy: 0.7765\n",
      "Epoch 2/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.6666 - accuracy: 0.7700 - val_loss: 0.5202 - val_accuracy: 0.8220\n",
      "Epoch 3/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.5655 - accuracy: 0.8029 - val_loss: 0.4755 - val_accuracy: 0.8358\n",
      "Epoch 4/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.5149 - accuracy: 0.8206 - val_loss: 0.4437 - val_accuracy: 0.8477\n",
      "Epoch 5/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.4788 - accuracy: 0.8316 - val_loss: 0.4247 - val_accuracy: 0.8526\n",
      "Epoch 6/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.4527 - accuracy: 0.8391 - val_loss: 0.4087 - val_accuracy: 0.8586\n",
      "Epoch 7/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.4339 - accuracy: 0.8472 - val_loss: 0.3915 - val_accuracy: 0.8635\n",
      "Epoch 8/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.4155 - accuracy: 0.8507 - val_loss: 0.3837 - val_accuracy: 0.8665\n",
      "Epoch 9/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.4033 - accuracy: 0.8558 - val_loss: 0.3755 - val_accuracy: 0.8657\n",
      "Epoch 10/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3915 - accuracy: 0.8592 - val_loss: 0.3698 - val_accuracy: 0.8673\n",
      "Epoch 11/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3810 - accuracy: 0.8632 - val_loss: 0.3590 - val_accuracy: 0.8711\n",
      "Epoch 12/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3698 - accuracy: 0.8665 - val_loss: 0.3542 - val_accuracy: 0.8740\n",
      "Epoch 13/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3621 - accuracy: 0.8693 - val_loss: 0.3527 - val_accuracy: 0.8729\n",
      "Epoch 14/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3540 - accuracy: 0.8716 - val_loss: 0.3492 - val_accuracy: 0.8761\n",
      "Epoch 15/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3457 - accuracy: 0.8762 - val_loss: 0.3417 - val_accuracy: 0.8795\n",
      "Epoch 16/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3384 - accuracy: 0.8776 - val_loss: 0.3415 - val_accuracy: 0.8791\n",
      "Epoch 17/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3336 - accuracy: 0.8799 - val_loss: 0.3347 - val_accuracy: 0.8828\n",
      "Epoch 18/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3297 - accuracy: 0.8809 - val_loss: 0.3321 - val_accuracy: 0.8824\n",
      "Epoch 19/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3219 - accuracy: 0.8846 - val_loss: 0.3320 - val_accuracy: 0.8831\n",
      "Epoch 20/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3184 - accuracy: 0.8838 - val_loss: 0.3288 - val_accuracy: 0.8840\n",
      "Epoch 21/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3114 - accuracy: 0.8874 - val_loss: 0.3258 - val_accuracy: 0.8846\n",
      "Epoch 22/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3065 - accuracy: 0.8888 - val_loss: 0.3196 - val_accuracy: 0.8868\n",
      "Epoch 23/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.3014 - accuracy: 0.8908 - val_loss: 0.3218 - val_accuracy: 0.8865\n",
      "Epoch 24/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2989 - accuracy: 0.8911 - val_loss: 0.3184 - val_accuracy: 0.8877\n",
      "Epoch 25/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2949 - accuracy: 0.8938 - val_loss: 0.3209 - val_accuracy: 0.8872\n",
      "Epoch 26/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2908 - accuracy: 0.8952 - val_loss: 0.3139 - val_accuracy: 0.8920\n",
      "Epoch 27/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2876 - accuracy: 0.8950 - val_loss: 0.3167 - val_accuracy: 0.8883\n",
      "Epoch 28/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2811 - accuracy: 0.8966 - val_loss: 0.3203 - val_accuracy: 0.8867\n",
      "Epoch 29/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2765 - accuracy: 0.8995 - val_loss: 0.3143 - val_accuracy: 0.8905\n",
      "Epoch 30/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2728 - accuracy: 0.9002 - val_loss: 0.3131 - val_accuracy: 0.8903\n",
      "Epoch 31/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2688 - accuracy: 0.9017 - val_loss: 0.3146 - val_accuracy: 0.8915\n",
      "Epoch 32/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2662 - accuracy: 0.9032 - val_loss: 0.3154 - val_accuracy: 0.8884\n",
      "Epoch 33/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2628 - accuracy: 0.9045 - val_loss: 0.3191 - val_accuracy: 0.8900\n",
      "Epoch 34/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2592 - accuracy: 0.9052 - val_loss: 0.3093 - val_accuracy: 0.8923\n",
      "Epoch 35/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2580 - accuracy: 0.9057 - val_loss: 0.3080 - val_accuracy: 0.8943\n",
      "Epoch 36/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2537 - accuracy: 0.9073 - val_loss: 0.3062 - val_accuracy: 0.8934\n",
      "Epoch 37/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2522 - accuracy: 0.9078 - val_loss: 0.3125 - val_accuracy: 0.8902\n",
      "Epoch 38/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2487 - accuracy: 0.9070 - val_loss: 0.3048 - val_accuracy: 0.8955\n",
      "Epoch 39/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2415 - accuracy: 0.9124 - val_loss: 0.3062 - val_accuracy: 0.8948\n",
      "Epoch 40/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2450 - accuracy: 0.9108 - val_loss: 0.3047 - val_accuracy: 0.8918\n",
      "Epoch 41/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2368 - accuracy: 0.9137 - val_loss: 0.3042 - val_accuracy: 0.8944\n",
      "Epoch 42/50\n",
      "384/384 [==============================] - 2s 4ms/step - loss: 0.2338 - accuracy: 0.9145 - val_loss: 0.3058 - val_accuracy: 0.8927\n",
      "Epoch 43/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2310 - accuracy: 0.9146 - val_loss: 0.3033 - val_accuracy: 0.8960\n",
      "Epoch 44/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2323 - accuracy: 0.9137 - val_loss: 0.3041 - val_accuracy: 0.8979\n",
      "Epoch 45/50\n",
      "384/384 [==============================] - 2s 4ms/step - loss: 0.2269 - accuracy: 0.9159 - val_loss: 0.3037 - val_accuracy: 0.8960\n",
      "Epoch 46/50\n",
      "384/384 [==============================] - 2s 4ms/step - loss: 0.2234 - accuracy: 0.9195 - val_loss: 0.3062 - val_accuracy: 0.8968\n",
      "Epoch 47/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2230 - accuracy: 0.9179 - val_loss: 0.2995 - val_accuracy: 0.8977\n",
      "Epoch 48/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2182 - accuracy: 0.9198 - val_loss: 0.3089 - val_accuracy: 0.8961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "384/384 [==============================] - 1s 4ms/step - loss: 0.2180 - accuracy: 0.9207 - val_loss: 0.3087 - val_accuracy: 0.8955\n",
      "Epoch 50/50\n",
      "384/384 [==============================] - 2s 4ms/step - loss: 0.2137 - accuracy: 0.9206 - val_loss: 0.3001 - val_accuracy: 0.8982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26c84542c10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Dropout: 과적합 방지 ===\n",
    "\n",
    "# Dropout: 과적합을 방지하기 위해 hidden layer의 몇 가지 노드를 비활성화.\n",
    "# 복잡도를 낮춤.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 모델 생성\n",
    "model = Sequential()\n",
    "\n",
    "# 모델에 레이어 추가\n",
    "# input layer\n",
    "model.add(Flatten(input_shape=(784,))) # 28*28\n",
    "# hidden layer\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.25)) # hideen layer 사이에 Dropout을 추가한다\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax')) # 0~9\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# 모델 설정\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']) # 평가 기준\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(x_data_train_norm, # val_accuracy: 0.8982\n",
    "          t_data_train,\n",
    "          epochs=50,\n",
    "          validation_split=0.2,\n",
    "          verbose=1,\n",
    "          batch_size=100)\n",
    "\n",
    "# 0.88 -> 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de1479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2957 - accuracy: 0.8967\n",
      "[0.2957453727722168, 0.8967499732971191]\n"
     ]
    }
   ],
   "source": [
    "# 만든 모델에 대한 최종 평가\n",
    "print(model.evaluate(x_data_test_norm, t_data_test)) # [0.2957453727722168, 0.8967499732971191]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
